---
title: "R Notebook"
output: html_notebook
---

```{r}
library(rpart)
library(rpart.plot)
library(tidyverse)
library(modelr)
library(yardstick)

titanic_set <- read_csv('data/titanic_decision_tree_data.csv')

shuffle_index <- sample(1:nrow(titanic_set))

# shuffle the data so class order isn't in order - need this for training/testing split later on 
titanic_set <- titanic_set[shuffle_index, ]
```

# Question 1 

Cleaning up the data is always the first step. Do the following:

Take only observations which have a survived flag (i.e. that aren’t missing)
Turn your important variables into factors (sex, survived, pclass, embarkation)
Create an age_status variable which groups individuals under (and including) 16 years of age into a category called “child” category and those over 16 into a category called “adult”.
Drop the NA
Drop any variables you don’t need (X1, passenger_id, name, ticket, far, cabin)

```{r}
clean_titanic_set <- titanic_set %>%
  filter(survived %in% c(1, 0)) %>%
  mutate(sex = as.factor(sex),
         age_status = as.factor(if_else(age <= 16, "child", "adult")),
         class = factor(pclass, levels = c(3,2,1), labels = c("Lower", "Middle", "Upper")), 
         survived_flag = factor(survived, levels = c(0,1), labels = c("No", "Yes")), 
         port_embarkation = as.factor(embarked)) %>%
  select(sex, age_status, class, port_embarkation, sib_sp, parch, survived_flag) %>%
  na.omit()
```

```{r}
clean_titanic_set
```
# Question 2

Have a look at your data and create some plots to ensure you know what you’re working with before you begin. Write a summary of what you have found in your plots. Which variables do you think might be useful to predict whether or not people are going to die? Knowing this before you start is the best way to have a sanity check that your model is doing a good job.

```{r}
library(GGally)
```
```{r fig.height=10, fig.width=10}
ggpairs(clean_titanic_set)
```
Of all the predictors id say sex and class appear to be fairly key indicators of survival 

# Question 3

Now you can start to build your model. Create your testing and training set using an appropriate split. Check you have balanced sets. Write down why you chose the split you did and produce output tables to show whether or not it is balanced.

```{r}
n_data <- nrow(clean_titanic_set)
test_index <- sample(1:n_data, size = 0.2 * n_data)
```
```{r}
titanic_test <- slice(clean_titanic_set, test_index)
titanic_train <- slice(clean_titanic_set, -test_index)
```
```{r}
titanic_test %>%
  janitor::tabyl(survived_flag)
```
```{r}
titanic_train %>%
  janitor::tabyl(survived_flag)
```

58.4% - 41.6%, No - Yes in test, 59.8% - 40.2%, No - Yes in the train set. This is pretty close and will do fine. The test set is also big enough. 

# Question 4

Create your decision tree to try and predict survival probability using an appropriate method, and create a decision tree plot.

```{r}
titanic_fit <- rpart(
  formula = survived_flag ~ . ,
  data = titanic_train,
  method = 'class'
)
```
```{r}
rpart.plot(titanic_fit, yesno = 2, fallen.leaves = T, faclen = 6, digits = 4, type = 4, extra = 101)
```

# Question 5

Write down what this tells you, in detail. What variables are important? What does each node tell you? Who has the highest chance of surviving? Who has the lowest? Provide as much detail as you can.

Answer:
percentages at each step show you the population of the dataset at each node, so for example the original 100% was split into 63.68% on the male branch, and 36.32% on the female branch. The numbers on the left and right indicate the survival rate at each node, so for example on the male side 291 people did not survive and 72 people did survive.

Highest chance of survival would be a middle to upper class female, with the lowest chance of survival being a male lower class adult. 

# Question 6

Test and add your predicitons to your data. Create a confusion matrix. Write down in detial what this tells you for this specific dataset.

```{r}
titanic_test_pred <- titanic_test %>%
  add_predictions(titanic_fit, type = "class")

titanic_test_pred
```

```{r}
conf_mat <- titanic_test_pred %>%
  conf_mat(truth = survived_flag, estimate = pred)

conf_mat
```
```{r}
accuracy <- titanic_test_pred %>%
  accuracy(truth = survived_flag, estimate = pred)

accuracy
```

For this test dataset, my predictions correctly predicted no 72 times and correctly predicted yes 37 times. It predicted no when the actual was yes 22 times and predicted yes when the actual was no 11 times, with an accuracy of 76.8%





